{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41aabf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfs_dir = 's3://projectnetflix/'\n",
    "training = dbfs_dir + 'TrainingRatings.txt'\n",
    "testing = dbfs_dir + 'TestingRatings.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e090b9",
   "metadata": {},
   "source": [
    "<h4> Defining the dataframe schema </h4>\n",
    "<p> The test and train schema are the same thus, defining a single schema </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e190b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "df_schema = StructType(\n",
    "  [StructField('movieID', IntegerType()),\n",
    "   StructField('userID', IntegerType()),\n",
    "   StructField('rating', DoubleType())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79659491",
   "metadata": {},
   "source": [
    "<h4> Reading the data </h4>\n",
    "<p>Creating dataframes with predefined schema for test and train data given to us initially <br>\n",
    "And caching them for future use</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd474c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train data =  3255352\n",
      "Total test data =  100478\n"
     ]
    }
   ],
   "source": [
    "training_data = sqlContext.read.format('csv').options(header=False, inferSchema=False).schema(df_schema).load(training)\n",
    "testing_data = sqlContext.read.format('csv').options(header=False, inferSchema=False).schema(df_schema).load(testing)\n",
    "\n",
    "training_data.cache()\n",
    "testing_data.cache()\n",
    "\n",
    "print('Total train data = ', training_data.count())\n",
    "print('Total test data = ', testing_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff786e",
   "metadata": {},
   "source": [
    "<h4> Creating a sample </h4>\n",
    "<p>Randomly selecting 20% of the data to create sample sets which can be used <br>\n",
    "    for quicker analysis of the test and train datasets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19bc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "\n",
    "sample_train = training_data.orderBy(rand(seed=5)).limit(651071)\n",
    "sample_test = testing_data.orderBy(rand(seed=5)).limit(20096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeeeb843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|  14137|1750812|   2.0|\n",
      "|  17334| 769887|   3.0|\n",
      "|    907|1300759|   5.0|\n",
      "|   3290|2524741|   3.0|\n",
      "+-------+-------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sample_train.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b414c183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|   6408| 116761|   3.0|\n",
      "|   6281|1944206|   4.0|\n",
      "|   7511|2487973|   4.0|\n",
      "|    442|1460499|   4.0|\n",
      "+-------+-------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_test.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4c1c0",
   "metadata": {},
   "source": [
    "<h4> Problem 2 a)</h4>\n",
    "<p>In order to be able to evaluate your approach the goal of your project is to predict the \n",
    "ratings for all user-item pairs in the test set (TestingRatings.txt). How many distinct \n",
    "items and how many distinct users are there in the test set (TestingRatings.txt)?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c46e1c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/14 18:21:44 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct items/movies in test set =  1701\n",
      "Distinct users in test set =  27555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct items/movies in training set =  1821\n",
      "Distinct users in training set =  28978\n"
     ]
    }
   ],
   "source": [
    "#Problem 2a)\n",
    "from pyspark.sql.functions import countDistinct\n",
    "sample_train.cache()\n",
    "sample_test.cache()\n",
    "\n",
    "distinct_items = testing_data.select(countDistinct('movieID'))\n",
    "print('Distinct items/movies in test set = ', distinct_items.collect()[0][0])\n",
    "\n",
    "distinct_users = testing_data.select(countDistinct('userID'))\n",
    "print('Distinct users in test set = ', distinct_users.collect()[0][0])\n",
    "\n",
    "distinct_items = training_data.select(countDistinct('movieID'))\n",
    "print('\\nDistinct items/movies in training set = ', distinct_items.collect()[0][0])\n",
    "\n",
    "distinct_users = training_data.select(countDistinct('userID'))\n",
    "print('Distinct users in training set = ', distinct_users.collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b70158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c692c05f",
   "metadata": {},
   "source": [
    "<h4> Problem 2 b)</h4>\n",
    "<p> Calculate estimated average overlap of items for users and estimated average overlap of users for items. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d2250a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated average overlap of items for users =  1872.3651925465838\n",
      "estimated average overlap of users for items =  44.29447349630012\n"
     ]
    }
   ],
   "source": [
    "#Problem 2b)\n",
    "\n",
    "#Randomly selecting 10 users to consider for calculating overlap - as list of userIDs\n",
    "randomly_selected_users = list(sample_test.select('userID').distinct().orderBy(rand()).limit(10)\\\n",
    "                               .select('userID').toPandas()['userID'])\n",
    "\n",
    "#Maintaining an average overlap List for multiple users\n",
    "avgOverlap = []\n",
    "\n",
    "for user in randomly_selected_users:\n",
    "    \n",
    "    #Fetch all the items that have been rated by given user\n",
    "    userRatings = sample_train.filter(sample_train.userID == user)\n",
    "    #print('\\nTotal items rated by user', user, ' = ', userRatings.select(countDistinct('movieID')).collect()[0][0])\n",
    "\n",
    "    #All items rated by given user - as a list\n",
    "    ratedMovies = list(userRatings.select('movieID').toPandas()['movieID'])\n",
    "    \n",
    "    #Counting number of users which rated the same movies/items as selected user\n",
    "    otherRatingCounts = sample_train.filter(sample_train.movieID.isin(ratedMovies)).groupBy('movieID')\\\n",
    "    .agg(countDistinct('userID').alias('count'))\n",
    "    \n",
    "    #Calculating average over all the items of selected user\n",
    "    itemOverlapForUser = list(otherRatingCounts.select('count').toPandas()['count'])\n",
    "    avgForUser = sum(itemOverlapForUser)/len(itemOverlapForUser)\n",
    "    avgOverlap.append(avgForUser)\n",
    "    #print('Average overlap of items for selected user =', avgForUser)\n",
    "\n",
    "#Calculating average overlap for multiple users from test set\n",
    "finalAvgOverlap = sum(avgOverlap)/len(avgOverlap)\n",
    "print('estimated average overlap of items for users = ', finalAvgOverlap)\n",
    "\n",
    "#========================\n",
    "\n",
    "#Randomly selecting 10 items to consider for calculating overlap - as list of movieIDs\n",
    "randomly_selected_items = list(sample_test.select('movieID').distinct().orderBy(rand()).limit(10)\\\n",
    "                               .select('movieID').toPandas()['movieID'])\n",
    "\n",
    "#Maintaining an average overlap List for multiple items\n",
    "avgOverlap = []\n",
    "\n",
    "for item in randomly_selected_items:\n",
    "    \n",
    "    #Fetch all the users that have rated given movie\n",
    "    userRatings = sample_train.filter(sample_train.movieID == item)\n",
    "    #print('\\nTotal users given rating for item', item, ' = ', userRatings.select(countDistinct('userID')).collect()[0][0])\n",
    "\n",
    "    #All users that rated given item - as a list\n",
    "    ratedMovies = list(userRatings.select('userID').toPandas()['userID'])\n",
    "    \n",
    "    #Counting number of items which were rated by the same user as selected movie\n",
    "    otherRatingCounts = sample_train.filter(sample_train.userID.isin(ratedMovies)).groupBy('userID')\\\n",
    "    .agg(countDistinct('movieID').alias('count'))\n",
    "    \n",
    "    #Calculating average over all the users of selected item\n",
    "    itemOverlapForUser = list(otherRatingCounts.select('count').toPandas()['count'])\n",
    "    avgForUser = sum(itemOverlapForUser)/len(itemOverlapForUser)\n",
    "    avgOverlap.append(avgForUser)\n",
    "    #print('Average overlap of user for selected item =', avgForUser)\n",
    "\n",
    "#Calculating average overlap for multiple items from test set\n",
    "finalAvgOverlap = sum(avgOverlap)/len(avgOverlap)\n",
    "print('estimated average overlap of users for items = ', finalAvgOverlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e84a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98843bab",
   "metadata": {},
   "source": [
    "<h3> Problem 2c) </h3>\n",
    "<p> From 2a :\n",
    "<ul>\n",
    "    <li>Distinct items/movies in test set =  1701</li>\n",
    "    <li>Distinct users in test set =  27555</li>\n",
    "    <br>\n",
    "    <li>Distinct items/movies in training set =  1821</li>\n",
    "    <li>Distinct users in training set =  28978</li>\n",
    "</ul>\n",
    "Since number of items << number of users,<br>\n",
    "it would be expected that the overlap of items >> overlap of users<br>\n",
    "This is because the SAME items could have been rated by MANY users<br>\n",
    "however, the SAME users might or might not have rated the SAME items<br>\n",
    "\n",
    "From 2b :\n",
    "<ul>\n",
    "    <li>estimated average overlap of items for users ~ 2287.272</li>\n",
    "    <li>estimated average overlap of users for items ~  34.645</li>\n",
    "</ul>\n",
    "\n",
    "As expected, the overlap of items is much higher than the overlap of users<br>\n",
    "\n",
    "From the calculations, <strong>higher overlap of items</strong>\n",
    "indicates the data has many <strong>similar users</strong>.<br>\n",
    "Thus, the predictions would likely be way more accurate if we were to use the <strong>user-user</strong> model\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcaa42d",
   "metadata": {},
   "source": [
    "<h4> Pearson correlation </h4>\n",
    "<p>item-item model</p>\n",
    "<sub>Unable to pivot data to be able to perfom user-user model - because of VERY HIGH number of users</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc54f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28978"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grouping data by userID and maintaining movie rating for each user\n",
    "item_item_train = (training_data.groupBy('userID').pivot('movieID').sum('rating'))\n",
    "item_item_train = item_item_train.na.fill(value=0)\n",
    "item_item_train.cache()\n",
    "\n",
    "item_item_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4db88e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userID: int, 8: double, 28: double, 43: double, 48: double, 61: double, 64: double, 66: double, 92: double, 96: double, 111: double, 122: double, 123: double, 127: double, 140: double, 145: double, 154: double, 156: double, 174: double, 185: double, 192: double, 207: double, 214: double, 218: double, 222: double, 229: double, 237: double, 259: double, 267: double, 276: double, 287: double, 305: double, 318: double, 323: double, 336: double, 359: double, 361: double, 380: double, 395: double, 398: double, 409: double, 417: double, 440: double, 442: double, 443: double, 450: double, 452: double, 481: double, 507: double, 510: double, 518: double, 541: double, 543: double, 557: double, 566: double, 577: double, 578: double, 583: double, 594: double, 595: double, 606: double, 626: double, 634: double, 636: double, 638: double, 642: double, 647: double, 655: double, 666: double, 669: double, 681: double, 712: double, 718: double, 722: double, 723: double, 725: double, 735: double, 740: double, 761: double, 779: double, 790: double, 795: double, 797: double, 813: double, 815: double, 816: double, 826: double, 827: double, 834: double, 844: double, 849: double, 850: double, 851: double, 852: double, 855: double, 865: double, 878: double, 885: double, 888: double, 907: double, 909: double, 911: double, 916: double, 923: double, 930: double, 946: double, 949: double, 960: double, 992: double, 1007: double, 1046: double, 1048: double, 1054: double, 1059: double, 1061: double, 1076: double, 1078: double, 1091: double, 1092: double, 1100: double, 1104: double, 1122: double, 1123: double, 1134: double, 1140: double, 1146: double, 1167: double, 1188: double, 1190: double, 1192: double, 1202: double, 1205: double, 1213: double, 1252: double, 1256: double, 1260: double, 1268: double, 1289: double, 1305: double, 1313: double, 1333: double, 1340: double, 1343: double, 1356: double, 1367: double, 1388: double, 1406: double, 1407: double, 1425: double, 1430: double, 1432: double, 1444: double, 1455: double, 1464: double, 1482: double, 1484: double, 1488: double, 1500: double, 1522: double, 1523: double, 1554: double, 1557: double, 1559: double, 1564: double, 1600: double, 1609: double, 1615: double, 1629: double, 1644: double, 1668: double, 1675: double, 1731: double, 1744: double, 1757: double, 1779: double, 1803: double, 1807: double, 1825: double, 1832: double, 1841: double, 1845: double, 1848: double, 1851: double, 1853: double, 1868: double, 1884: double, 1889: double, 1893: double, 1896: double, 1898: double, 1901: double, 1903: double, 1924: double, 1944: double, 1951: double, 1952: double, 1958: double, 1966: double, 1967: double, 1983: double, 1993: double, 2014: double, 2015: double, 2028: double, 2036: double, 2039: double, 2042: double, 2043: double, 2053: double, 2058: double, 2079: double, 2083: double, 2103: double, 2104: double, 2106: double, 2110: double, 2116: double, 2130: double, 2147: double, 2160: double, 2168: double, 2193: double, 2198: double, 2212: double, 2232: double, 2235: double, 2243: double, 2251: double, 2284: double, 2290: double, 2298: double, 2313: double, 2316: double, 2342: double, 2343: double, 2344: double, 2352: double, 2355: double, 2356: double, 2366: double, 2375: double, 2418: double, 2430: double, 2432: double, 2438: double, 2460: double, 2492: double, 2503: double, 2504: double, 2506: double, 2510: double, 2512: double, 2518: double, 2528: double, 2532: double, 2544: double, 2552: double, 2560: double, 2562: double, 2565: double, 2569: double, 2597: double, 2601: double, 2604: double, 2616: double, 2621: double, 2629: double, 2640: double, 2642: double, 2643: double, 2658: double, 2659: double, 2660: double, 2666: double, 2667: double, 2675: double, 2678: double, 2682: double, 2707: double, 2715: double, 2718: double, 2731: double, 2745: double, 2749: double, 2755: double, 2756: double, 2757: double, 2773: double, 2786: double, 2789: double, 2794: double, 2807: double, 2808: double, 2818: double, 2859: double, 2861: double, 2866: double, 2886: double, 2905: double, 2909: double, 2913: double, 2918: double, 2925: double, 2928: double, 2931: double, 2939: double, 2954: double, 2955: double, 2969: double, 2985: double, 2988: double, 2995: double, 3022: double, 3032: double, 3033: double, 3043: double, 3044: double, 3054: double, 3057: double, 3068: double, 3069: double, 3073: double, 3084: double, 3094: double, 3107: double, 3135: double, 3143: double, 3147: double, 3149: double, 3151: double, 3164: double, 3165: double, 3170: double, 3176: double, 3189: double, 3192: double, 3196: double, 3200: double, 3201: double, 3220: double, 3229: double, 3232: double, 3237: double, 3243: double, 3253: double, 3257: double, 3269: double, 3271: double, 3274: double, 3281: double, 3285: double, 3290: double, 3298: double, 3301: double, 3316: double, 3326: double, 3329: double, 3330: double, 3351: double, 3355: double, 3359: double, 3418: double, 3440: double, 3486: double, 3492: double, 3498: double, 3538: double, 3541: double, 3546: double, 3559: double, 3568: double, 3584: double, 3586: double, 3587: double, 3590: double, 3598: double, 3613: double, 3638: double, 3647: double, 3652: double, 3655: double, 3658: double, 3670: double, 3685: double, 3702: double, 3705: double, 3706: double, 3722: double, 3727: double, 3733: double, 3734: double, 3740: double, 3742: double, 3743: double, 3760: double, 3824: double, 3848: double, 3861: double, 3862: double, 3874: double, 3878: double, 3881: double, 3889: double, 3890: double, 3891: double, 3893: double, 3903: double, 3904: double, 3914: double, 3928: double, 3941: double, 3943: double, 3944: double, 3955: double, 3977: double, 3978: double, 3994: double, 4002: double, 4005: double, 4008: double, 4023: double, 4032: double, 4042: double, 4049: double, 4061: double, 4064: double, 4076: double, 4095: double, 4119: double, 4122: double, 4128: double, 4129: double, 4144: double, 4152: double, 4160: double, 4189: double, 4190: double, 4207: double, 4215: double, 4218: double, 4224: double, 4238: double, 4239: double, 4257: double, 4264: double, 4268: double, 4272: double, 4283: double, 4299: double, 4329: double, 4346: double, 4359: double, 4385: double, 4394: double, 4405: double, 4429: double, 4432: double, 4439: double, 4441: double, 4445: double, 4468: double, 4485: double, 4496: double, 4513: double, 4518: double, 4538: double, 4544: double, 4546: double, 4552: double, 4556: double, 4563: double, 4566: double, 4569: double, 4574: double, 4586: double, 4613: double, 4619: double, 4627: double, 4637: double, 4640: double, 4645: double, 4647: double, 4685: double, 4694: double, 4737: double, 4742: double, 4750: double, 4761: double, 4768: double, 4811: double, 4837: double, 4840: double, 4847: double, 4849: double, 4852: double, 4858: double, 4868: double, 4875: double, 4876: double, 4880: double, 4901: double, 4902: double, 4918: double, 4921: double, 4932: double, 4935: double, 4943: double, 4952: double, 4963: double, 4966: double, 4981: double, 4986: double, 5008: double, 5025: double, 5026: double, 5027: double, 5062: double, 5069: double, 5096: double, 5098: double, 5123: double, 5129: double, 5131: double, 5142: double, 5143: double, 5149: double, 5157: double, 5159: double, 5160: double, 5175: double, 5206: double, 5220: double, 5225: double, 5267: double, 5272: double, 5284: double, 5294: double, 5311: double, 5326: double, 5327: double, 5336: double, 5337: double, 5342: double, 5361: double, 5364: double, 5367: double, 5369: double, 5408: double, 5425: double, 5426: double, 5465: double, 5474: double, 5484: double, 5485: double, 5552: double, 5556: double, 5562: double, 5568: double, 5577: double, 5604: double, 5607: double, 5623: double, 5640: double, 5641: double, 5651: double, 5656: double, 5699: double, 5700: double, 5716: double, 5727: double, 5729: double, 5748: double, 5760: double, 5766: double, 5785: double, 5790: double, 5799: double, 5813: double, 5814: double, 5827: double, 5835: double, 5849: double, 5877: double, 5883: double, 5897: double, 5898: double, 5901: double, 5911: double, 5921: double, 5941: double, 5943: double, 5945: double, 5958: double, 5963: double, 5966: double, 5970: double, 5979: double, 6013: double, 6014: double, 6066: double, 6069: double, 6085: double, 6086: double, 6093: double, 6103: double, 6110: double, 6121: double, 6131: double, 6136: double, 6137: double, 6140: double, 6172: double, 6177: double, 6190: double, 6200: double, 6208: double, 6215: double, 6220: double, 6226: double, 6228: double, 6230: double, 6234: double, 6250: double, 6252: double, 6257: double, 6260: double, 6276: double, 6277: double, 6281: double, 6285: double, 6287: double, 6289: double, 6291: double, 6308: double, 6315: double, 6318: double, 6334: double, 6336: double, 6338: double, 6347: double, 6354: double, 6356: double, 6358: double, 6363: double, 6389: double, 6390: double, 6395: double, 6400: double, 6405: double, 6406: double, 6408: double, 6417: double, 6419: double, 6424: double, 6446: double, 6448: double, 6466: double, 6467: double, 6480: double, 6481: double, 6482: double, 6522: double, 6523: double, 6529: double, 6536: double, 6537: double, 6541: double, 6543: double, 6550: double, 6556: double, 6562: double, 6566: double, 6567: double, 6593: double, 6611: double, 6619: double, 6629: double, 6650: double, 6663: double, 6666: double, 6668: double, 6678: double, 6680: double, 6714: double, 6737: double, 6743: double, 6748: double, 6756: double, 6830: double, 6839: double, 6871: double, 6872: double, 6885: double, 6889: double, 6892: double, 6894: double, 6901: double, 6911: double, 6912: double, 6914: double, 6917: double, 6919: double, 6932: double, 6939: double, 6946: double, 6965: double, 6971: double, 6975: double, 6979: double, 6985: double, 6988: double, 6991: double, 6998: double, 7011: double, 7016: double, 7022: double, 7030: double, 7033: double, 7061: double, 7063: double, 7067: double, 7068: double, 7075: double, 7077: double, 7084: double, 7089: double, 7109: double, 7116: double, 7132: double, 7136: double, 7137: double, 7145: double, 7147: double, 7148: double, 7186: double, 7188: double, 7236: double, 7238: double, 7244: double, 7247: double, 7255: double, 7257: double, 7262: double, 7273: double, 7283: double, 7292: double, 7299: double, 7329: double, 7334: double, 7339: double, 7382: double, 7386: double, 7387: double, 7400: double, 7406: double, 7408: double, 7418: double, 7437: double, 7442: double, 7445: double, 7458: double, 7466: double, 7476: double, 7495: double, 7503: double, 7505: double, 7511: double, 7512: double, 7516: double, 7517: double, 7518: double, 7524: double, 7527: double, 7537: double, 7544: double, 7551: double, 7557: double, 7567: double, 7569: double, 7571: double, 7577: double, 7587: double, 7607: double, 7625: double, 7638: double, 7656: double, 7681: double, 7698: double, 7721: double, 7726: double, 7736: double, 7747: double, 7763: double, 7768: double, 7770: double, 7776: double, 7801: double, 7802: double, 7806: double, 7812: double, 7822: double, 7823: double, 7838: double, 7858: double, 7868: double, 7899: double, 7901: double, 7903: double, 7906: double, 7916: double, 7919: double, 7921: double, 7923: double, 7931: double, 7939: double, 7950: double, 7968: double, 7973: double, 7991: double, 8002: double, 8005: double, 8007: double, 8008: double, 8017: double, 8023: double, 8029: double, 8039: double, 8051: double, 8052: double, 8058: double, 8072: double, 8085: double, 8096: double, 8107: double, 8121: double, 8128: double, 8162: double, 8163: double, 8166: double, 8182: double, 8200: double, 8206: double, 8207: double, 8220: double, 8249: double, 8260: double, 8268: double, 8307: double, 8315: double, 8341: double, 8352: double, 8354: double, 8365: double, 8384: double, 8390: double, 8392: double, 8401: double, 8422: double, 8428: double, 8435: double, 8448: double, 8452: double, 8458: double, 8488: double, 8491: double, 8493: double, 8495: double, 8512: double, 8526: double, 8534: double, 8537: double, 8560: double, 8561: double, 8566: double, 8582: double, 8594: double, 8596: double, 8628: double, 8654: double, 8657: double, 8661: double, 8677: double, 8678: double, 8692: double, 8697: double, 8699: double, 8703: double, 8706: double, 8718: double, 8738: double, 8766: double, 8770: double, 8781: double, 8798: double, 8804: double, 8825: double, 8842: double, 8849: double, 8851: double, 8867: double, 8889: double, 8896: double, 8905: double, 8915: double, 8919: double, 8920: double, 8921: double, 8933: double, 8951: double, 8977: double, 8994: double, 9025: double, 9028: double, 9043: double, 9046: double, 9059: double, 9087: double, 9093: double, 9107: double, 9130: double, 9131: double, 9152: double, 9167: double, 9186: double, 9187: double, 9199: double, 9202: double, 9230: double, 9237: double, 9256: double, 9297: double, 9310: double, 9324: double, 9337: double, 9343: double, 9376: double, 9401: double, 9404: double, 9410: double, 9421: double, 9422: double, 9423: double, 9481: double, 9482: double, 9492: double, 9517: double, 9518: double, 9528: double, 9530: double, 9537: double, 9550: double, 9551: double, 9567: double, 9568: double, 9600: double, 9602: double, 9607: double, 9612: double, 9617: double, 9620: double, 9629: double, 9632: double, 9640: double, 9650: double, 9672: double, 9681: double, 9689: double, 9691: double, 9696: double, 9697: double, 9699: double, 9701: double, 9716: double, 9717: double, 9719: double, 9720: double, 9728: double, 9730: double, 9735: double, 9744: double, 9747: double, 9750: double, 9752: double, 9767: double, 9798: double, 9805: double, 9817: double, 9819: double, 9824: double, 9831: double, 9843: double, 9854: double, 9855: double, 9867: double, 9875: double, 9885: double, 9890: double, 9897: double, 9920: double, 9930: double, 9945: double, 9946: double, 9953: double, 9967: double, 9973: double, 9989: double, 9993: double, 9997: double, 10006: double, 10019: double, 10024: double, 10025: double, 10034: double, 10048: double, 10076: double, 10077: double, 10080: double, 10082: double, 10089: double, 10100: double, 10104: double, 10108: double, 10109: double, 10127: double, 10187: double, 10188: double, 10194: double, 10195: double, 10219: double, 10237: double, 10248: double, 10255: double, 10284: double, 10319: double, 10321: double, 10349: double, 10350: double, 10354: double, 10368: double, 10391: double, 10404: double, 10415: double, 10428: double, 10429: double, 10462: double, 10493: double, 10522: double, 10540: double, 10555: double, 10561: double, 10572: double, 10576: double, 10578: double, 10589: double, 10595: double, 10659: double, 10662: double, 10663: double, 10670: double, 10676: double, 10686: double, 10692: double, 10712: double, 10721: double, 10733: double, 10734: double, 10735: double, 10743: double, 10747: double, 10750: double, 10757: double, 10762: double, 10774: double, 10777: double, 10780: double, 10781: double, 10792: double, 10800: double, 10810: double, 10826: double, 10835: double, 10836: double, 10843: double, 10845: double, 10846: double, 10851: double, 10870: double, 10889: double, 10900: double, 10903: double, 10921: double, 10926: double, 10939: double, 10943: double, 10947: double, 10959: double, 10978: double, 10992: double, 11003: double, 11007: double, 11009: double, 11011: double, 11021: double, 11025: double, 11027: double, 11034: double, 11041: double, 11048: double, 11054: double, 11056: double, 11076: double, 11080: double, 11086: double, 11088: double, 11098: double, 11107: double, 11124: double, 11133: double, 11158: double, 11159: double, 11177: double, 11182: double, 11197: double, 11213: double, 11232: double, 11235: double, 11236: double, 11237: double, 11238: double, 11240: double, 11245: double, 11253: double, 11259: double, 11261: double, 11284: double, 11286: double, 11288: double, 11292: double, 11294: double, 11295: double, 11307: double, 11312: double, 11316: double, 11317: double, 11319: double, 11330: double, 11339: double, 11340: double, 11344: double, 11347: double, 11348: double, 11352: double, 11376: double, 11380: double, 11391: double, 11395: double, 11408: double, 11412: double, 11418: double, 11436: double, 11442: double, 11463: double, 11493: double, 11496: double, 11505: double, 11510: double, 11511: double, 11513: double, 11536: double, 11563: double, 11567: double, 11613: double, 11614: double, 11616: double, 11631: double, 11637: double, 11638: double, 11651: double, 11657: double, 11673: double, 11686: double, 11688: double, 11689: double, 11690: double, 11723: double, 11732: double, 11757: double, 11766: double, 11775: double, 11786: double, 11806: double, 11812: double, 11824: double, 11829: double, 11835: double, 11837: double, 11838: double, 11839: double, 11851: double, 11866: double, 11867: double, 11884: double, 11887: double, 11888: double, 11902: double, 11908: double, 11923: double, 11951: double, 11952: double, 11965: double, 11966: double, 12010: double, 12046: double, 12059: double, 12100: double, 12117: double, 12123: double, 12125: double, 12133: double, 12156: double, 12159: double, 12170: double, 12178: double, 12180: double, 12184: double, 12189: double, 12199: double, 12202: double, 12230: double, 12232: double, 12243: double, 12246: double, 12273: double, 12275: double, 12276: double, 12280: double, 12284: double, 12291: double, 12292: double, 12293: double, 12298: double, 12336: double, 12348: double, 12355: double, 12372: double, 12386: double, 12391: double, 12396: double, 12413: double, 12419: double, 12421: double, 12422: double, 12423: double, 12432: double, 12452: double, 12455: double, 12472: double, 12482: double, 12488: double, 12496: double, 12497: double, 12503: double, 12504: double, 12510: double, 12538: double, 12544: double, 12589: double, 12604: double, 12606: double, 12607: double, 12623: double, 12627: double, 12634: double, 12639: double, 12653: double, 12661: double, 12679: double, 12682: double, 12683: double, 12695: double, 12700: double, 12705: double, 12709: double, 12733: double, 12755: double, 12757: double, 12760: double, 12775: double, 12778: double, 12780: double, 12793: double, 12795: double, 12798: double, 12812: double, 12822: double, 12824: double, 12847: double, 12852: double, 12855: double, 12863: double, 12864: double, 12875: double, 12887: double, 12894: double, 12912: double, 12920: double, 12936: double, 12946: double, 12948: double, 12952: double, 12957: double, 12969: double, 12977: double, 12993: double, 13015: double, 13022: double, 13032: double, 13046: double, 13055: double, 13059: double, 13099: double, 13107: double, 13110: double, 13137: double, 13145: double, 13150: double, 13154: double, 13186: double, 13188: double, 13199: double, 13212: double, 13215: double, 13218: double, 13235: double, 13242: double, 13262: double, 13270: double, 13288: double, 13289: double, 13298: double, 13299: double, 13305: double, 13326: double, 13328: double, 13334: double, 13339: double, 13360: double, 13363: double, 13377: double, 13387: double, 13431: double, 13432: double, 13438: double, 13451: double, 13456: double, 13461: double, 13464: double, 13477: double, 13485: double, 13489: double, 13507: double, 13519: double, 13531: double, 13561: double, 13563: double, 13565: double, 13569: double, 13587: double, 13589: double, 13590: double, 13601: double, 13604: double, 13606: double, 13608: double, 13614: double, 13632: double, 13633: double, 13636: double, 13638: double, 13651: double, 13664: double, 13674: double, 13677: double, 13680: double, 13682: double, 13686: double, 13744: double, 13748: double, 13758: double, 13760: double, 13769: double, 13783: double, 13787: double, 13802: double, 13817: double, 13823: double, 13828: double, 13831: double, 13835: double, 13838: double, 13853: double, 13858: double, 13861: double, 13877: double, 13878: double, 13887: double, 13899: double, 13905: double, 13909: double, 13911: double, 13912: double, 13927: double, 13934: double, 13936: double, 13938: double, 13964: double, 13965: double, 13989: double, 14013: double, 14046: double, 14070: double, 14072: double, 14075: double, 14077: double, 14079: double, 14086: double, 14088: double, 14089: double, 14096: double, 14099: double, 14100: double, 14136: double, 14137: double, 14144: double, 14154: double, 14169: double, 14171: double, 14177: double, 14185: double, 14189: double, 14198: double, 14199: double, 14203: double, 14209: double, 14216: double, 14231: double, 14234: double, 14244: double, 14248: double, 14255: double, 14258: double, 14272: double, 14279: double, 14282: double, 14283: double, 14290: double, 14292: double, 14314: double, 14317: double, 14320: double, 14324: double, 14329: double, 14335: double, 14347: double, 14354: double, 14361: double, 14372: double, 14380: double, 14386: double, 14392: double, 14407: double, 14429: double, 14430: double, 14440: double, 14442: double, 14457: double, 14459: double, 14462: double, 14469: double, 14470: double, 14484: double, 14492: double, 14496: double, 14503: double, 14505: double, 14506: double, 14518: double, 14537: double, 14551: double, 14552: double, 14560: double, 14575: double, 14581: double, 14594: double, 14611: double, 14625: double, 14643: double, 14645: double, 14648: double, 14712: double, 14716: double, 14720: double, 14722: double, 14732: double, 14738: double, 14740: double, 14743: double, 14775: double, 14793: double, 14800: double, 14807: double, 14808: double, 14810: double, 14826: double, 14836: double, 14859: double, 14902: double, 14904: double, 14930: double, 14932: double, 14941: double, 14947: double, 14957: double, 14962: double, 14983: double, 14995: double, 15005: double, 15020: double, 15033: double, 15040: double, 15051: double, 15060: double, 15071: double, 15074: double, 15083: double, 15085: double, 15115: double, 15121: double, 15122: double, 15135: double, 15142: double, 15150: double, 15152: double, 15153: double, 15160: double, 15165: double, 15175: double, 15183: double, 15192: double, 15201: double, 15202: double, 15213: double, 15214: double, 15216: double, 15222: double, 15223: double, 15228: double, 15234: double, 15246: double, 15251: double, 15257: double, 15272: double, 15276: double, 15331: double, 15338: double, 15371: double, 15378: double, 15391: double, 15409: double, 15410: double, 15413: double, 15428: double, 15438: double, 15449: double, 15464: double, 15469: double, 15475: double, 15478: double, 15480: double, 15496: double, 15507: double, 15510: double, 15515: double, 15516: double, 15527: double, 15529: double, 15532: double, 15536: double, 15539: double, 15547: double, 15557: double, 15567: double, 15568: double, 15576: double, 15582: double, 15592: double, 15610: double, 15629: double, 15632: double, 15648: double, 15657: double, 15661: double, 15662: double, 15670: double, 15676: double, 15687: double, 15691: double, 15695: double, 15707: double, 15712: double, 15714: double, 15716: double, 15726: double, 15731: double, 15741: double, 15754: double, 15763: double, 15772: double, 15785: double, 15808: double, 15809: double, 15816: double, 15820: double, 15830: double, 15836: double, 15841: double, 15842: double, 15855: double, 15911: double, 15915: double, 15929: double, 15946: double, 15951: double, 15955: double, 15961: double, 15962: double, 15981: double, 15982: double, 15992: double, 15993: double, 15998: double, 16000: double, 16001: double, 16018: double, 16021: double, 16022: double, 16035: double, 16042: double, 16046: double, 16055: double, 16066: double, 16082: double, 16091: double, 16112: double, 16120: double, 16122: double, 16127: double, 16129: double, 16131: double, 16132: double, 16135: double, 16147: double, 16150: double, 16153: double, 16157: double, 16162: double, 16169: double, 16188: double, 16231: double, 16232: double, 16243: double, 16246: double, 16247: double, 16252: double, 16256: double, 16262: double, 16277: double, 16283: double, 16286: double, 16300: double, 16311: double, 16329: double, 16335: double, 16342: double, 16344: double, 16349: double, 16396: double, 16398: double, 16408: double, 16410: double, 16422: double, 16444: double, 16451: double, 16456: double, 16467: double, 16477: double, 16488: double, 16494: double, 16506: double, 16540: double, 16545: double, 16554: double, 16555: double, 16559: double, 16563: double, 16572: double, 16576: double, 16589: double, 16599: double, 16606: double, 16613: double, 16627: double, 16629: double, 16663: double, 16670: double, 16685: double, 16689: double, 16705: double, 16707: double, 16726: double, 16731: double, 16733: double, 16741: double, 16761: double, 16762: double, 16770: double, 16784: double, 16787: double, 16788: double, 16790: double, 16797: double, 16820: double, 16830: double, 16849: double, 16854: double, 16869: double, 16889: double, 16902: double, 16904: double, 16906: double, 16915: double, 16916: double, 16928: double, 16931: double, 16933: double, 16948: double, 16950: double, 16955: double, 16970: double, 16975: double, 16982: double, 16986: double, 16988: double, 16993: double, 16996: double, 16999: double, 17020: double, 17056: double, 17065: double, 17068: double, 17074: double, 17082: double, 17085: double, 17087: double, 17090: double, 17104: double, 17107: double, 17124: double, 17137: double, 17174: double, 17182: double, 17196: double, 17202: double, 17203: double, 17232: double, 17255: double, 17290: double, 17304: double, 17310: double, 17324: double, 17326: double, 17334: double, 17337: double, 17338: double, 17344: double, 17348: double, 17358: double, 17394: double, 17411: double, 17423: double, 17447: double, 17454: double, 17466: double, 17515: double, 17522: double, 17523: double, 17534: double, 17536: double, 17551: double, 17554: double, 17556: double, 17558: double, 17561: double, 17574: double, 17616: double, 17624: double, 17626: double, 17635: double, 17640: double, 17642: double, 17650: double, 17653: double, 17654: double, 17660: double, 17689: double, 17693: double, 17706: double, 17725: double, 17728: double, 17734: double, 17741: double, 17742: double, ratingsVector: vector]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Maintaining a list of all movieIDs in the training data\n",
    "allCol = []\n",
    "for col in item_item_train.dtypes:\n",
    "    allCol.append(col[0])\n",
    "allCol.remove('userID')\n",
    "\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "#Creating a ratings vector - list all all ratings by that user for different movies(0 for null)\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=allCol,\n",
    "    outputCol=\"ratingsVector\")\n",
    "\n",
    "output = assembler.transform(item_item_train)\n",
    "output.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcc1b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.toPandas().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10838cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "import numpy as np\n",
    "\n",
    "#Forming the correlation matrix on the pearson method\n",
    "correlation_matrix = Correlation.corr(output, 'ratingsVector', 'pearson')\n",
    "mat = correlation_matrix.collect()[0][0].toArray()\n",
    "allColArray = np.array(allCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d4837b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity of one movie with another is as below:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8</th>\n",
       "      <th>28</th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>61</th>\n",
       "      <th>64</th>\n",
       "      <th>66</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>111</th>\n",
       "      <th>...</th>\n",
       "      <th>17654</th>\n",
       "      <th>17660</th>\n",
       "      <th>17689</th>\n",
       "      <th>17693</th>\n",
       "      <th>17706</th>\n",
       "      <th>17725</th>\n",
       "      <th>17728</th>\n",
       "      <th>17734</th>\n",
       "      <th>17741</th>\n",
       "      <th>17742</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042146</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>-0.014675</td>\n",
       "      <td>-0.000750</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>0.012119</td>\n",
       "      <td>-0.000779</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033358</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>-0.030664</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.043411</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.018934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.042146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>0.110906</td>\n",
       "      <td>-0.009361</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.123198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101463</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.157262</td>\n",
       "      <td>0.019206</td>\n",
       "      <td>-0.025760</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.015772</td>\n",
       "      <td>0.003481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037607</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>0.050806</td>\n",
       "      <td>0.046491</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.028172</td>\n",
       "      <td>-0.008141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.030161</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.131892</td>\n",
       "      <td>0.009742</td>\n",
       "      <td>0.025317</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>0.024677</td>\n",
       "      <td>0.020845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.014675</td>\n",
       "      <td>0.110906</td>\n",
       "      <td>0.037607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022967</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>0.050921</td>\n",
       "      <td>0.052250</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.012718</td>\n",
       "      <td>0.030831</td>\n",
       "      <td>0.078753</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>0.042453</td>\n",
       "      <td>0.012585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.000750</td>\n",
       "      <td>-0.009361</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>0.022967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051848</td>\n",
       "      <td>0.086510</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.037186</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.044564</td>\n",
       "      <td>0.116404</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>0.024588</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.027635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17725</th>\n",
       "      <td>0.025023</td>\n",
       "      <td>-0.025760</td>\n",
       "      <td>0.009742</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>0.024588</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.013599</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>0.030360</td>\n",
       "      <td>0.016149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006480</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.018162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>0.008061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17728</th>\n",
       "      <td>0.043411</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>0.025317</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>0.036705</td>\n",
       "      <td>0.028801</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.053833</td>\n",
       "      <td>-0.011111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001303</td>\n",
       "      <td>0.012518</td>\n",
       "      <td>0.059656</td>\n",
       "      <td>-0.003611</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.026911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.078206</td>\n",
       "      <td>0.066338</td>\n",
       "      <td>0.051135</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005808</td>\n",
       "      <td>0.085926</td>\n",
       "      <td>0.072782</td>\n",
       "      <td>0.015864</td>\n",
       "      <td>0.059971</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018625</td>\n",
       "      <td>0.032018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17741</th>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.015772</td>\n",
       "      <td>0.024677</td>\n",
       "      <td>0.042453</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.032127</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.052028</td>\n",
       "      <td>0.006804</td>\n",
       "      <td>0.039247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>0.015954</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>0.039082</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.018625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17742</th>\n",
       "      <td>0.018934</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.020845</td>\n",
       "      <td>0.012585</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.057850</td>\n",
       "      <td>0.057945</td>\n",
       "      <td>0.036698</td>\n",
       "      <td>0.045001</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016719</td>\n",
       "      <td>0.042896</td>\n",
       "      <td>0.053636</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>0.032018</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows  1821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                8        28        43        48        61        64        66  \\\n",
       "movieID                                                                         \n",
       "8        1.000000 -0.042146  0.005975 -0.014675 -0.000750  0.012873  0.012119   \n",
       "28      -0.042146  1.000000  0.014497  0.110906 -0.009361  0.001573  0.004635   \n",
       "43       0.005975  0.014497  1.000000  0.037607  0.025534  0.050806  0.046491   \n",
       "48      -0.014675  0.110906  0.037607  1.000000  0.022967  0.028974  0.050921   \n",
       "61      -0.000750 -0.009361  0.025534  0.022967  1.000000  0.051848  0.086510   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "17725    0.025023 -0.025760  0.009742  0.030731  0.024588  0.008251  0.013599   \n",
       "17728    0.043411 -0.015913  0.025317  0.001624  0.028530  0.036705  0.028801   \n",
       "17734    0.026431  0.002747  0.016258  0.015319  0.042600  0.075105  0.078206   \n",
       "17741    0.005980  0.015772  0.024677  0.042453  0.014583  0.032127  0.054287   \n",
       "17742    0.018934  0.003481  0.020845  0.012585  0.027635  0.057850  0.057945   \n",
       "\n",
       "               92        96       111  ...     17654     17660     17689  \\\n",
       "movieID                                ...                                 \n",
       "8       -0.000779  0.022855 -0.023613  ... -0.033358  0.036393  0.007312   \n",
       "28       0.003757  0.009357  0.123198  ...  0.101463  0.004686  0.003791   \n",
       "43       0.005333  0.028172 -0.008141  ...  0.015749  0.005587  0.030161   \n",
       "48       0.052250  0.031889 -0.000721  ...  0.034976  0.012718  0.030831   \n",
       "61       0.079832  0.037186  0.000258  ...  0.005865  0.044564  0.116404   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "17725    0.023541  0.030360  0.016149  ...  0.006480  0.011732  0.026723   \n",
       "17728    0.008176  0.053833 -0.011111  ... -0.001303  0.012518  0.059656   \n",
       "17734    0.066338  0.051135  0.002920  ... -0.005808  0.085926  0.072782   \n",
       "17741    0.052028  0.006804  0.039247  ...  0.002104  0.023743  0.015954   \n",
       "17742    0.036698  0.045001  0.002495  ...  0.016719  0.042896  0.053636   \n",
       "\n",
       "            17693     17706     17725     17728     17734     17741     17742  \n",
       "movieID                                                                        \n",
       "8       -0.030664  0.001916  0.025023  0.043411  0.026431  0.005980  0.018934  \n",
       "28       0.157262  0.019206 -0.025760 -0.015913  0.002747  0.015772  0.003481  \n",
       "43       0.013084  0.131892  0.009742  0.025317  0.016258  0.024677  0.020845  \n",
       "48       0.078753  0.050127  0.030731  0.001624  0.015319  0.042453  0.012585  \n",
       "61       0.023404  0.025427  0.024588  0.028530  0.042600  0.014583  0.027635  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "17725    0.009913  0.018162  1.000000  0.013895  0.020327 -0.003775  0.008061  \n",
       "17728   -0.003611  0.005868  0.013895  1.000000  0.029439  0.002085  0.026911  \n",
       "17734    0.015864  0.059971  0.020327  0.029439  1.000000  0.018625  0.032018  \n",
       "17741    0.014572  0.039082 -0.003775  0.002085  0.018625  1.000000  0.014102  \n",
       "17742    0.028344  0.025900  0.008061  0.026911  0.032018  0.014102  1.000000  \n",
       "\n",
       "[1821 rows x 1821 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#viewing the correlation matrix as a pandas dataframe for easier visualization\n",
    "pearsonCorr = pd.DataFrame(mat, columns=allCol)\n",
    "pearsonCorr['movieID'] = allCol\n",
    "pearsonCorr = pearsonCorr.set_index('movieID')\n",
    "\n",
    "print('The similarity of one movie with another is as below:')\n",
    "pearsonCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2c34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b364cbd7",
   "metadata": {},
   "source": [
    "<h4> Problem 2d) </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e6c28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 142:============================>                            (4 + 4) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|rating|  count|\n",
      "+------+-------+\n",
      "|   1.0| 169886|\n",
      "|   2.0| 374452|\n",
      "|   3.0|1048538|\n",
      "|   4.0|1044293|\n",
      "|   5.0| 618183|\n",
      "+------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "training_data.groupBy('rating').count().orderBy('rating').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290eeb0b",
   "metadata": {},
   "source": [
    "With the count of each rating in the training set, it is significant that all of the ratings can be significant<br> (although ratings 3 and 4 have the most weightage)<br>\n",
    "\n",
    "If I were to normalize the ratings, it would mean changing the rating scale from 1-5 to any other target rating. <br>\n",
    "However, I would not like to do so since the 1-5 ratings are way more natural and easy to understand (than suppose a 1-3 rating).\n",
    "<br>\n",
    "<br>\n",
    "In addition to that, since the test set could still have lower rated movies, it would be unfair to remove them from the predictions.<br> However, the lower rated movies can be filtered out during recommendation. It is always much better to suggest highly rated movies rather than poorly rated ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d3ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7822b894",
   "metadata": {},
   "source": [
    "<h3> Problem 3 </h3>\n",
    "<p>3a) Prediction using item-item model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda3fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import numpy as np\n",
    "\n",
    "#Method to getch the top 15 movies correlated to current movie\n",
    "def top15(row):\n",
    "\n",
    "    item = row.movieID\n",
    "    user = row.userID\n",
    "    \n",
    "    #Get the position of current movie in all movies\n",
    "    pos = allCol.index(str(item))\n",
    "    \n",
    "    #Fetch the indexes of top 15 movies matches as current movie\n",
    "    ind = np.argpartition(mat[pos], -15)[-15:]\n",
    "    \n",
    "    #Map top 15 indexes to top 15 movies\n",
    "    top_n = allColArray[ind]\n",
    "    top_n = [int(x) for x in top_n]\n",
    "    \n",
    "    return Row(movieID=item, top=top_n, userID=user, rating=row.rating)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e89e0966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|   6408| 116761|   3.0|\n",
      "|   6281|1944206|   4.0|\n",
      "|   7511|2487973|   4.0|\n",
      "|    442|1460499|   4.0|\n",
      "|   8851|1739230|   3.0|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Uncomment to try on larger data set\n",
    "#small = sample_test.limit(700)\n",
    "small = sample_test.limit(10)\n",
    "small.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba1cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = small.rdd.map(lambda x : top15(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66d3c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining and creating a dataframe for final ratings\n",
    "df_schema = StructType(\n",
    "  [StructField('movieID', IntegerType()),\n",
    "   StructField('userID', IntegerType()),\n",
    "   StructField('rating', DoubleType()),\n",
    "  StructField('pred', DoubleType())]\n",
    ")\n",
    "\n",
    "final = spark.createDataFrame(sc.emptyRDD(), df_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c4cd52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieID: integer (nullable = true)\n",
      " |-- userID: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- pred: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14a57d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "#Predicting the ratings\n",
    "def predictRating(row):\n",
    "    \n",
    "    item = row.movieID\n",
    "    user = row.userID\n",
    "    \n",
    "    top_n = row.top\n",
    "    \n",
    "    #Fetch the ratings by current user for top 15 similar movies\n",
    "    ratings = training_data.filter((training_data.movieID.isin(top_n)) & (training_data.userID == user))\n",
    "    ratings = ratings.select('rating').rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    if len(ratings) >= 5:\n",
    "        pred = round(sum(ratings)/len(ratings), 2)\n",
    "   \n",
    "    #If current user has not rated atlease 5 of top 15 movies, consider average of all user ratings\n",
    "    else:\n",
    "        ratings = training_data.filter((training_data.movieID.isin(top_n)))\\\n",
    "        .groupBy('movieID').agg(avg('rating').alias('rating'))\n",
    "        ratings = ratings.select('rating').rdd.flatMap(lambda x: x).collect()\n",
    "        pred = round(sum(ratings)/len(ratings), 2)\n",
    "        \n",
    "    return spark.createDataFrame([(item, user, row.rating, pred)], df_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "844d2f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 s, sys: 4.6 s, total: 22.2 s\n",
      "Wall time: 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Manually working with each row individually since\n",
    "#external dataframes can not be accessed with rdd functions (map, foreach, etc)\n",
    "for row in preds.collect():\n",
    "    #Adding predicted rating for each test row\n",
    "    final = final.union(predictRating(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cf08563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----+\n",
      "|movieID| userID|rating|pred|\n",
      "+-------+-------+------+----+\n",
      "|   6408| 116761|   3.0| 3.5|\n",
      "|   6281|1944206|   4.0|3.57|\n",
      "|   7511|2487973|   4.0| 4.0|\n",
      "|    442|1460499|   4.0| 4.0|\n",
      "+-------+-------+------+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This is what the dataframe with predictions looks like\n",
    "#Basically, it is the same as test dataframe, with a new column called pred\n",
    "final.cache()\n",
    "final.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4343acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For item-item model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1531:=================================================>(5596 + 4) / 5600]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE is 0.7394\n",
      "The RMSE is 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Evaluating the mae and rmse for the predictions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "print('For item-item model:')\n",
    "mae_eval = RegressionEvaluator(predictionCol=\"pred\", labelCol=\"rating\", metricName=\"mae\")\n",
    "rmse_eval = RegressionEvaluator(predictionCol=\"pred\", labelCol=\"rating\", metricName=\"rmse\")\n",
    "\n",
    "mae = mae_eval.evaluate(final)\n",
    "rmse = rmse_eval.evaluate(final)\n",
    "\n",
    "print('The MAE is %.4f' % mae)\n",
    "print('The RMSE is %.4f' % rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee4b76",
   "metadata": {},
   "source": [
    "<p>When the same prediction was done for lesser data (100 records), the MAE was around 0.91<br>\n",
    "    with around 300 records, the MAE was ~ 0.86 <br>\n",
    "    with more test data (700 records), the MAE is ~ 0.74. <br>\n",
    "    This is enough to expect that for more records, the MAE could go further below. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db439ada",
   "metadata": {},
   "source": [
    "<h3> Problem 3 </h3>\n",
    "3b) Recommendation using item-item model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d7ce079",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_user_id = 4\n",
    "\n",
    "my_rated_movies = [\n",
    "    (my_user_id, 10676, 4),\n",
    "    (my_user_id, 14810, 4),\n",
    "    (my_user_id, 16162, 2),\n",
    "    (my_user_id, 11340, 5),\n",
    "    (my_user_id, 4556, 2),\n",
    "    (my_user_id, 6250, 4),\n",
    "    (my_user_id, 13334, 1),\n",
    "    (my_user_id, 11312, 1),\n",
    "    (my_user_id, 15731, 5),\n",
    "    (my_user_id, 10109, 4)]\n",
    "\n",
    "my_rated_movies = sqlContext.createDataFrame(my_rated_movies, ['userID','movieID','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c83a8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My rated movies are:\n",
      "+-------+------+------+-----------+-----------------------------------+\n",
      "|movieID|userID|rating|releaseYear|title                              |\n",
      "+-------+------+------+-----------+-----------------------------------+\n",
      "|10676  |4     |4     |1933       |The Kennel Murder Case / Nancy Drew|\n",
      "|14810  |4     |4     |2000       |Dolphins: IMAX                     |\n",
      "|16162  |4     |2     |2002       |Kim Possible: The Secret Files     |\n",
      "|11340  |4     |5     |1988       |Johnny Be Good                     |\n",
      "|4556   |4     |2     |2001       |Stealing Time                      |\n",
      "|6250   |4     |4     |1997       |Female Perversions                 |\n",
      "|13334  |4     |1     |2000       |Catfish in Black Bean Sauce        |\n",
      "|11312  |4     |1     |1998       |Mystery Kids                       |\n",
      "|15731  |4     |5     |2002       |Roxy Music: Live at the Apollo     |\n",
      "|10109  |4     |4     |1994       |Major League II                    |\n",
      "+-------+------+------+-----------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = dbfs_dir + 'movie_titles.txt'\n",
    "movie_schema = StructType(\n",
    "  [StructField('movieID', IntegerType()),\n",
    "   StructField('releaseYear', IntegerType()),\n",
    "   StructField('title', StringType())]\n",
    ")\n",
    "\n",
    "movie_data = sqlContext.read.format('csv').options(header=False, inferSchema=False).schema(movie_schema).load(movies)\n",
    "movie_data.cache()\n",
    "\n",
    "my_rated_movies = my_rated_movies.join(movie_data,on=['movieID'],how='inner')\n",
    "print('My rated movies are:')\n",
    "my_rated_movies.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "190968d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 153 ms, sys: 22.2 ms, total: 175 ms\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def getRecMovies():\n",
    "    #Fetch all MY movies with higher ratings\n",
    "    my_top = my_rated_movies.filter(my_rated_movies.rating > 3).select('movieID')\n",
    "    my_top = my_top.rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    topRecs = []\n",
    "    for item in my_top:\n",
    "        pos = allCol.index(str(item))\n",
    "        \n",
    "        ind = np.argpartition(mat[pos], -3)[-3:]\n",
    "        top_n = allColArray[ind]\n",
    "        top_n = [int(x) for x in top_n]\n",
    "        for x in top_n:\n",
    "            topRecs.append(x)\n",
    "        topRecs.remove(item)\n",
    "\n",
    "    df_schema = StructType([StructField('movieID', IntegerType()),\n",
    "                            StructField('avgRating', DoubleType())])\n",
    "    \n",
    "    recs = spark.createDataFrame(sc.emptyRDD(), df_schema)\n",
    "    \n",
    "    for item in topRecs:\n",
    "        avR = round(training_data.filter(training_data.movieID == item).\\\n",
    "                    groupBy('movieID').agg(avg('rating').alias('rating')).collect()[0][1], 2)\n",
    "        recs = recs.union(spark.createDataFrame([(item, avR)], df_schema))\n",
    "    \n",
    "    return recs\n",
    "\n",
    "recs = getRecMovies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "212f904d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for my user:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1577:================================================>     (87 + 8) / 96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-------+-----------+---------+\n",
      "|title                                     |movieID|releaseYear|avgRating|\n",
      "+------------------------------------------+-------+-----------+---------+\n",
      "|Sherlock Holmes: Terror by Night          |15676  |1946       |3.69     |\n",
      "|Charlie Chan: The Chinese Cat             |10195  |1944       |3.42     |\n",
      "|Wildcats                                  |6523   |1986       |3.38     |\n",
      "|Youngblood                                |2352   |1986       |3.21     |\n",
      "|Encino Man                                |3670   |1992       |3.03     |\n",
      "|Search for the Great Sharks: IMAX         |8121   |1999       |2.99     |\n",
      "|Genesis: Live at Wembley Stadium          |5921   |2004       |2.97     |\n",
      "|Niagara: Miracles                         |834    |1999       |2.96     |\n",
      "|Teen Wolf / Teen Wolf Too (Double Feature)|2284   |1985       |2.91     |\n",
      "|The Story of O                            |1252   |1975       |2.9      |\n",
      "|Young Adam                                |12679  |2004       |2.71     |\n",
      "|Lenny Kravitz: Live                       |10187  |2002       |2.23     |\n",
      "+------------------------------------------+-------+-----------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('Recommended movies for my user:')\n",
    "recs.orderBy('avgRating', ascending=False).join(movie_data,on=['movieID'],how='inner').\\\n",
    "select('title', 'movieID', 'releaseYear', 'avgRating').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66053938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: int, releaseYear: int, title: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manually clear all cachd RDDs\n",
    "testing_data.unpersist()\n",
    "training_data.unpersist()\n",
    "\n",
    "sample_test.unpersist()\n",
    "sample_train.unpersist()\n",
    "\n",
    "item_item_train.unpersist()\n",
    "output.unpersist()\n",
    "final.unpersist()\n",
    "movie_data.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51362e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
